---
title: "Censored quantile regression with partially functional effects"
author: "Stephen Lauer & Emily Peterson"
date: "April 28, 2017"
output:
    beamer_presentation:
      includes:
        in_header: slide-numbers.tex
      keep_tex: yes
---
### Overall Purpose

- Quantile regression offers felxibility in assessing covariate effects on event times.
- Develop quantile regression approach for survival subject to conditionally independent censoring.
-Tailor regression to partially functional effect setting. (Both varying and constant effects) 
- Martingale based estimating equations lead to single algorithm that invovles minimizing L1-type convex functions.
- Establish properties of estimators.


## Background on quantile regression

- Each covariate effect varies by quantile.
- For event time of interest $Y$ and covariate vector $W$, a quantile regression model assumes the $\tau$th quantile of $Y$ is given by:

$$
\begin{aligned}
Q_{Y}(\tau)&= F^{-1}_{Y}(\tau)\equiv \inf \{y: F_{Y}(y)\geq \tau\}, \quad \tau\in(0,1) \\
Q_{Y}(\tau|W)&= W^{T}\beta(\tau)
\end{aligned}
$$

- $Q_{Y}(\tau|W) \equiv inf{y: pr(Y \leq y | W) \geq \tau}$ denotes $\tau$th conditional quantile of $Y$ given $W$.
- Describes linear relationship between $W$ and $\tau$th quantile.
- Quantile function is minimum value of time $T$ below which subject will fall $p\times 100$ percent of times.

## Partially functional effects
- $\beta(\tau)$ represents effect of $W$ on $Q_{Y}(\tau|W)$
- Coefficients for $W$ are allowed to be function of $\tau$ meaning they are allowed to be related to both shape and location of distribution, not just a measure of central tendency.
- Partially Function Effects:
    - A model which includes a mixture of constant and varying effects.
    - $\tau$-varying coefficients correspond to effects allowed to vary by quantile group. 
- May be preferred to fully functional model due to more accurate quantile prediction for small $\tau$



## Censored quantile regression
Let $T$ and $C$ denote survival and censoring time.

$X = \min(T,C)$ and $\delta = I(T \leq C)$ where $I(\cdot)$ is indicator function.

$Y = \log T$

Partition $W$ into constant and quantile varying effects
$$
W=(Z^{T}, V^{T})^{T}
$$

$Z$ is $p\times 1$ vector of $\tau$ varying effects.

$V$ is $q\times 1$ vector of constant effects.

Data: $\{(X_{i}, \delta_{i}, Z_{i}, V_{i}),\quad i=1,...,n\}$

\textbf{Reminder:}

(a) CDF: $F_{T}(t|Z,V)= \Pr(T \leq t|Z,V)$
(b) Survival Function: $S(t)= Pr(T\geq t|Z,V) = 1-F_{T}(t|Z,V)$
(c) Cumulative Hazard Function: $\Lambda(t)= -\log S(t)= -\log (1-F_{T}(t|Z,V))$

## Partially functional quantile regression model

$$
Q_{Y}(\tau|Z,V) = Z^{T}\beta(\tau) + V^{T}\gamma, \quad \tau \in (0,1)
$$

- How do we account for the censoring?
- Monotone profile estimating equation!

## Martingale process
- To estimate $\beta(\tau)$, idea is to use stochastic property of martingale. 
- One jump counting process: gives information about when events occur. i.e. If person $i$ is "failure" by time $t$.
$$
N_{i}(t)= I(X_{i}\leq t, \delta_{i}=1)
$$

- Indicator if survival/censored time is above/equal to $t$
$$
Y_{i}(t)= I(X_{i}\geq t)
$$

- Martingale counting process wrt $F_{t}$, given by $M(t)= N(t)-\Lambda(t)$
$$M(t) = N(t) -\int_{0}^{t} Y(s)d\Lambda_{T}(s|Z,V)$$




- Non-decreasing step function minus a compensator (Cumulative Hazard Function)

- Mean-zero white noise
$$
E[M(t)|V,Z]=0
$$
    

## Estimating equation (Peng \& Huang, 2008)

- Approach for random censoring is to extend the Martingale representation of the Nelson-Aalen estimator of cumulative hazard to produce an estimating equation.
- Aim: to get $\beta$ and $\gamma$. 

- NA estimator: non-parametric estimator of the cumulative hazard rate function in case of censored data given by 
$$\tilde{H}(t)= \sum_{t_i \leq t}\frac{d_i}{n_i}$$
\noindent
with $d_i$ denote number of events at $t_i$ and $n_i$ is total number at risk at $t_i$. 



## The Estimating equation
$$
\begin{split}
    \text{E} \Bigg [ n^{-1/2}\sum_{i=1}^{n}\omega_{i} \bigg (N_{i} \exp \{Z_{i}^{T} \beta_{0} (\tau) + V_{i}^{T}\gamma_{0}\} - \\ \int_{0}^{\tau} I \Big [X_{i} \geq \exp \{Z_{i}^{T} \beta_{0} (u) + V_{i}^{T}\gamma_{0}\} \Big ] dH(u) \bigg ) \Bigg ] \\ = 0
\end{split}
$$

- $\beta_{0}$ and $\gamma_{0}$ are true values of $\beta$ and $\gamma$.
- Indicator $= \Lambda_{i}[\exp \{Z_{i}^{T} \beta_{0} (\tau) + V_{i}^{T} \gamma_{0} \}]$

## Computing Algorithm
- Step 1: Get $\widehat{\beta}(\tau_{j}, \gamma)$ with $\gamma$ fixed.

$$
\begin{split}
n^{-1} \sum_{i=1}^{n} Z_{i} \Bigg ( N_{i} \exp \{Z_{i}^{T} \widehat{\beta}(\tau_{j}) + V_{i}^{T}\gamma\} - \\
\sum_{k=0}^{j-1} I \bigg [X_{i} \geq \exp \{Z_{i}^{T} \widehat{\beta} (\tau_k, \gamma) + V_{i}^{T} \gamma)\} \bigg ] \Big ( H(\tau_{k+1}) - H(\tau_k) \Big) \Bigg) \\
=0
\end{split}
$$

Solve for $\beta(\tau_j)$

## Computing Algorithm 
- Step 2: Get $\widehat{\gamma}$ with $\widehat{\beta}(\tau_j)$ fixed.
$$
\begin{split}
n^{-1} \sum_{i=1}^{n} V_{i} \Bigg( N_{i} \exp \{ Z_{i}^{T} \widehat{\beta}(\tau_{j}) + V_{i}^{T} \gamma \} - \\
\sum_{k=0}^{L-1} I \bigg [X_{i} \geq \exp \{Z_{i}^{T} \widehat{\beta} (\tau_k, \gamma) + V_{i}^{T} \gamma \} \bigg ] \Big (H(\tau_{k+1})-H(\tau_k ) \Big) \Bigg ) \\
=0
\end{split}
$$

Solve for $\gamma$

- Step 3...

Iterate until convergence criteria is met.


## L1-type Optimization
- Finds roots of equations via optimization techniques
- Accomplished by linear programming techniques to get $\widehat{\beta}$ and $\widehat{\gamma}$ that minimizes function.
+ Step 1: Set $m=0$ and choose initial $\widehat{\gamma}^{m}$
+ Step 2: Find $\widehat{\beta}^{(m)}(\tau_j, \widehat{\gamma}^{(m)})$
$$
\begin{split}
l_j (h) = \sum_{i=1}^n \left | \delta_i \left (\log X_i - V_i^T \widehat{\gamma}^{(m)} - Z_i^T h \right ) \right | + \left | R^* - \sum_{l=1}^n \left (- \delta_l Z_l^T h \right ) \right | + \\ \Bigg | R^* - \sum_{r=1}^n \Bigg ( 2 Z_r^T h \sum_{k=0}^{j-1} I \left [ X_r \geq \exp \left \{ Z_i^T \widehat{\beta}^{(m)} + V_i^T \widehat{\gamma}^{(m)} \right \} \right ] \\ \left \{ H(\tau_{k+1}) - H(\tau_k) \right \} \Bigg ) \Bigg | 
\end{split}
$$


##
+ Step 3: Find $\widehat{\gamma}^{(m+1)}$ given estimate for $\beta^{(m)}$ from step 2.
$$
\begin{split}
l^{*}(h) = \sum_{i=1}^{n} \left |\delta_i \{ \log X_i - Z_{i}^{T} \widehat{\beta}^{(m)} - V_{i}^{T} h \} \right | + \left | R^{*} - \sum_{l=1}^{n} (-\delta_{l} V_{l}^{T} h) \right | + \\ \sum_{k=0}^{L-1} \Bigg [ \sum_{i=1}^{n} \left | \{ \log X_i - Z_{i}^{T} \widehat{\beta}^{(m)} - V_i^T h \} \{ H (\tau_{k+1}) - H (\tau_k) \} \right | + \\ \left | R^{*} - \sum_{r=1}^{n} (-V_{r}^{T} h) \{ H (\tau_{k+1}) - H (\tau_k) \} \right | \Bigg ] + \left | R^{*} - \sum_{s=1}^{n} 2 V_{s}^{T} h H (\tau_L ) \right |
\end{split}
$$

+ Step 4: Update $m$ to $m+1$ and repeat steps 2-3 until convergence criteria met.

## Asymptotic Properties

- Theorem 1:  Shows consistency, as $n\rightarrow \infty$, estimates converge to the truth, so they are \textbf{unbiased} estimators.
$$\widehat{\gamma}\rightarrow \gamma_0 \mbox { in probability }$$
$$ sup||\widehat{\beta}(\tau)-\beta_0 (\tau)||\rightarrow 0 \mbox{ in probability }$$

- Theorem 2: Asymptotic Distributions
$$n^{1/2}(\widehat{\gamma} - \gamma_0 )\sim^{\mathrm{asymp}}N(0, E[...])$$
$$n^{1/2}(\widehat{\beta}(\tau)- \beta_0(\tau))\rightarrow GT(\tau)$$
+ Generalization of asymptotic normality for parameter that is function of $\tau$. 


## Resampling-based inference procedure

- The limit distributions of $\frac{\widehat{\gamma}-\gamma_0}{\sqrt{n}}$ and $\frac{\widehat{\beta}(\tau)-\beta_0(\tau)}{\sqrt{n}}$ involve unknown density functions
- The estimation of these distributions may not be stable with a small or moderate sample size
- The authors proposed a new resampling approach similar to that of wild bootstrapping

## Resampling-based inference procedure

1) Draw $n$ idd nonnegative variates of a known distribution with a mean and variance of 1, e.g.:
$$
\xi_i \sim \exp(1)
$$
2) Solve estimating equations on slides 12 and 13 perturbed by $\xi_i$
$$
\begin{split}
\tilde{l}_{j}(h) = \sum_{i=1}^n \left | \xi_i \delta_i \left ( log X_i - V_i^T \gamma^{*(m)} - Z_i^{T}h \right ) \right | + \\ \left | R^{*} - \sum_{l=1}^{n} \left ( -\xi_l \delta_l Z_l^T h \right ) \right | + \\ \Bigg | R^* - \sum_{r=1}^n \Bigg ( 2 \xi_i Z_r^T h \sum_{k=0}^{j-1} I \left [ X_r \geq exp{Z_{i}^{T} \beta^{*(m)} + V_i^T \gamma^{*(m)}} \right ] \\ \left \{ H(\tau_{k+1}) - H(\tau_k) \right \} \Bigg ) \Bigg | 
\end{split}
$$

## Resampling-based inference procedure

2 continued)
$$
\begin{split}
\tilde{l}^*(h) = \sum_{i=1}^n \left | \xi_i \delta_i \left \{ log X_i - Z_i^T \beta^{*(m)} - V_i^T h \right \} \right | + \\ \left | R^* - \sum_{l=1}^n \left ( - \xi_l \delta_lV_l^T h \right ) \right | + \\ \sum_{k=0}^{L-1} \Bigg [ \sum_{i=1}^n \left | \xi_i \left \{ \log X_i - Z_i^T \beta^{*(m)} - V_i^T h  \right \} \left \{ H (\tau_{k+1}) - H (\tau_k) \right \} \right | + \\ \left | R^{*} - \sum_{r=1}^{n} (-\xi_r V_{r}^{T} h) \left \{ H (\tau_{k+1}) - H (\tau_k ) \right \} \right | \Bigg ] + \left | R^{*} - \sum_{s=1}^{n} 2 \xi_s V_{s}^{T} h H ( \tau_L ) \right |
\end{split}
$$

3) Repeat $K$ times

## Resampling-based inference procedure

- The variance of $\widehat{\beta}(\tau)$ and $\widehat{\gamma}$ can be estimated by the sample variance of $\{\beta_k^*(\tau)\}^K_{k=1}$ and $\{\gamma^*\}^K_{k=1}$
- A confidence intervals can be constructed using normal approximations or by using the empirical percentiles
- The conditional variance and covariance of the resampled estimating equations converge to the unconditional variance and covariance of the original estimating equations
- The conditional distribution of $n^{1/2} (\gamma^* - \widehat{\gamma})$ converges to the unconditional distribution of $n^{1/2} (\widehat{\gamma} - \gamma_0)$, same for $\beta^* (\tau), \widehat{\beta} (\tau), \beta_0 (\tau)$
- Has better numerical performance than a nonparametric bootstrap

## Simulation study: overview

Simulations were conducted to assess the finite-sample performace of the proposed method versus the Peng-Huang estimator in the following metrics:

- bias
- variance
- the impact of varying the following parameters on estimator efficiency:
    - sample size
    - number of covariates
    - dependency among covariates
    - censoring proportion
    - error heteroscedasticity
- also, computing time

## Simulation study: bias and variance

![Bias, empirical bias x$10^3$; EstVar, average of resampling-based variance estimates x$10^3$; EmpVar, empirical variances x$10^3$ Cov95, empirical coverage probabilities of 95% confidence intervals; VarRed, variance reduction of the proposed estimator over the Peng-Huang estimator (%)](figures/simulation-efficiency.jpg)

## Simulation study: impact of varying parameters

- Sample size
    - proposed estimator is root $n$ convergent, like Peng-Huang
- Number of covariates
    - With more covariates, the variance reduction relative to the Peng-Huang estimator decreases
- Dependency among covariates
    - Dependent covariates are associated with a slight increase in variance reduction in $\gamma$ and decreases in relative efficiency of $\beta$, especially at small values of $\tau$
- Censoring proportion
    - More censoring is associated slight decreases in constant coefficient efficiency and no effect on functional coefficients
- Error heteroscedasticity
    - Variance reduction shifts from intercept estimation to functional and constant coefficients

## Case study: renal disease

- A prospective study to investigate the risk factors in a cohort of 191 incidnt dialysis patients recruited from 26 facilities
- 35% of survival times censored due to renal transplant or the end of the study
- Covariates:
    - Patient age
    - Fish consumption in first year of dialysis (1 if any, 0 o.w.)
    - Baseline dialysis modality (1 if hemodialysis, 0 o.w.)
    - Education level (1 if high school or higher, 0 o.w.)
    - Race (1 if black, 0 o.w.)
    - Severe restless leg symptoms (1 if present, 0 o.w.)

## Discussion